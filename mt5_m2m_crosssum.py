# -*- coding: utf-8 -*-
"""mT5_m2m_crossSum.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18IK-p5HuSv3Uj87UFTNbIH1MGel1VQ8g
"""

!pip install transformers
!pip install sentencepiece

from transformers import AutoModel, AutoTokenizer
import re
import pandas as pd
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
WHITESPACE_HANDLER = lambda k: re.sub('\s+', ' ', re.sub('\n+', ' ', k.strip()))
model_name = "csebuetnlp/mT5_m2m_crossSum"
tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
get_lang_id = lambda lang: tokenizer._convert_token_to_id(model.config.task_specific_params["langid_map"][lang][1])

from google.colab import drive
#drive.mount('/content/drive')


def generate(article_text,target_lang):
  input_ids = tokenizer(
      [WHITESPACE_HANDLER(article_text)],
      return_tensors="pt",
      padding="max_length",
      truncation=True,
      max_length=512
  )["input_ids"]
  output_ids = model.generate(
      input_ids=input_ids,
      decoder_start_token_id=get_lang_id(target_lang),
      max_length=84,
      no_repeat_ngram_size=2,
      num_beams=4,
  )[0]
  return output_ids

#change pathname
#path="/content/drive/My Drive/test.csv"
path="eng_mini.csv"
df = pd.read_csv(path)
print(df.head())


n=len(df)
n

target_lang = "english" #give target language
given_id=[]
generated_summary=[]
for i in range(n):
  article_text=df.iloc[i]['Article']
  given_id.append(df.iloc[i]['id'])
  output_ids=generate(article_text,target_lang)
  summary = tokenizer.decode(
    output_ids,
    skip_special_tokens=True,
    clean_up_tokenization_spaces=False
  )
  generated_summary.append(summary)
  print(i)

k = pd.DataFrame({'id':given_id,'summary':generated_summary})

# saving the dataframe
k.to_csv('file2.csv')